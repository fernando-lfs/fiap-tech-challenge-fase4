# üìà Tech Challenge - Fase 4: Previs√£o de A√ß√µes com MLOps

> **Deep Learning & AI - FIAP**

Este projeto consiste em uma solu√ß√£o completa de **End-to-End Machine Learning** para prever o pre√ßo de fechamento de a√ß√µes da **CEMIG (CMIG4.SA)**. 

A solu√ß√£o abrange desde a coleta e pr√©-processamento de dados financeiros at√© o treinamento de uma rede neural **LSTM** (Long Short-Term Memory) utilizando **PyTorch Lightning** e **MLflow** , disponibilizando o modelo final atrav√©s de uma API **FastAPI** robusta e containerizada com **Docker**. O sistema conta ainda com suporte a treinamento ass√≠ncrono e monitoramento em tempo real de **Data Drift** para garantir a confiabilidade das previs√µes em produ√ß√£o.

---

## üöÄ Funcionalidades Principais

* **Coleta & Baseline:** Download autom√°tico via `yfinance` e gera√ß√£o de estat√≠sticas descritivas para detec√ß√£o de anomalias.
* **Treinamento Padronizado:** Pipeline utilizando `PyTorch Lightning` para organizar loops de treino/valida√ß√£o e `EarlyStopping`.
* **Rastreamento (Tracking):** Registro autom√°tico de hiperpar√¢metros, m√©tricas (Loss, MAPE) e artefatos (modelos `.pth`, gr√°ficos) via **MLflow**.
* **API Gerenci√°vel:** Interface RESTful que permite n√£o apenas prever, mas tamb√©m disparar **retreinos em background** e atualizar configura√ß√µes dinamicamente.
* **Observabilidade de Dados:** O endpoint de predi√ß√£o detecta automaticamente **Data Drift** (mudan√ßas bruscas de padr√£o ou volatilidade) comparando a entrada com o baseline de treino.
* **Escalabilidade:** Arquitetura desenhada para execu√ß√£o em containers e orquestra√ß√£o.

---

## üõ†Ô∏è Stack Tecnol√≥gico

* **Linguagem:** Python 3.11
* **Gerenciamento:** Poetry
* **Deep Learning:** PyTorch, PyTorch Lightning
* **MLOps:** MLflow
* **API:** FastAPI, Uvicorn, Pydantic
* **Dados:** Pandas, Numpy, Scikit-Learn, Yahoo Finance
* **Infraestrutura:** Docker

---

## üèóÔ∏è Arquitetura e Decis√µes T√©cnicas (ADR)

Para atender aos requisitos de qualidade de engenharia, as seguintes decis√µes foram tomadas:

1. **PyTorch Lightning:** Adotado para remover *boilerplate code* (loops manuais) e padronizar o c√≥digo de treinamento, facilitando a manuten√ß√£o e a reprodutibilidade.
2. **MLflow:** Escolhido como ferramenta de *Tracking* por ser agn√≥stico √† infraestrutura (roda localmente ou na nuvem) e permitir versionamento claro de cada experimento.
3. **FastAPI com BackgroundTasks:** Para o endpoint de treinamento (`/train`), utilizamos processamento ass√≠ncrono. Isso impede que uma requisi√ß√£o de treino bloqueie a API, mantendo-a responsiva para infer√™ncias simult√¢neas.
4. **Detec√ß√£o de Drift "In-App":** Optou-se por implementar um detector estat√≠stico leve dentro da pr√≥pria API (compara√ß√£o com Baseline JSON). Isso garante monitoramento de qualidade imediato sem a complexidade/custo de ferramentas externas pesadas (como Evidently AI) para este escopo acad√™mico.

---

## üìÇ Estrutura do Projeto

```text
/
‚îú‚îÄ‚îÄ api/                  # Aplica√ß√£o Web e Logs Centralizados
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Endpoints (Train, Predict, Config)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py       # Configura√ß√£o de Logging
‚îú‚îÄ‚îÄ data/                 # Data Lake (Raw e Processed)
‚îú‚îÄ‚îÄ mlruns/               # Registro local do MLflow (Metadados dos experimentos)
‚îú‚îÄ‚îÄ models/               # Artefatos: .pth, .joblib e baseline_stats.json
‚îú‚îÄ‚îÄ results/              # Gr√°ficos gerados
‚îú‚îÄ‚îÄ scripts/              # Pipelines ETL e Treino
‚îÇ   ‚îú‚îÄ‚îÄ 01_coleta_dados.py
‚îÇ   ‚îú‚îÄ‚îÄ 02_preprocess.py  # Gera dados normalizados e Baseline de Drift
‚îÇ   ‚îú‚îÄ‚îÄ 03_train.py       # Treino com Lightning + MLflow
‚îÇ   ‚îú‚îÄ‚îÄ 04_evaluate.py    # Avalia√ß√£o em dados de teste
|   ‚îî‚îÄ‚îÄ __init__.py       # Configura√ß√£o de Logging
‚îú‚îÄ‚îÄ src/                  # C√≥digo Fonte Reutiliz√°vel
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ model.py
|   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ mlflow.db
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requiriments.txt
```

---

## üìà Performance e Resultados

O modelo final (LSTM com 2 camadas, 64 neur√¥nios) atingiu os seguintes resultados nos dados de teste:

| M√©trica                    | Valor     |
| -------------------------- | --------- |
| **MAPE** (Erro Percentual) | **1.56%** |
| **MAE** (Erro Absoluto)    | R$ 0.16   |
| **RMSE** (Erro Quadr√°tico) | R$ 0.19   |

> **Nota:** Todos os gr√°ficos de perda e m√©tricas detalhadas podem ser visualizados via `mlflow ui`.

---

## ‚ö° Como Executar o Projeto

### Op√ß√£o 1: Via Docker (Produ√ß√£o)

1. **Construir a imagem:**
   
   ```bash
   docker build -t lstm-mlops .
   ```

2. **Rodar o container:**
   
   ```bash
   docker run -d -p 8000:8000 --name api-lstm lstm-mlops
   ```

3. **Acessar:**
* Swagger UI: `http://localhost:8000/docs`

---

### Op√ß√£o 2: Execu√ß√£o Local (Desenvolvimento & Experimentos)

1. **Instalar depend√™ncias:**
   
   ```bash
   poetry install
   poetry shell
   ```

2. **Executar Pipeline Completo (ETL + Treino):**
   
   ```bash
   # 1. Coleta e Preprocessamento (Gera baseline_stats.json)
   python -m scripts.01_coleta_dados
   python -m scripts.02_preprocess
   # 2. Treinamento (Registra no MLflow)
   python -m scripts.03_train
   # 3. Avalia√ß√£o
   python -m scripts.04_evaluate
   ```

   ‚ö†Ô∏è **Aten√ß√£o:** √â obrigat√≥rio executar o script `02_preprocess.py` antes de iniciar a API ou o treinamento. Este script gera o arquivo `baseline_stats.json`, essencial para que o detector de Drift funcione corretamente. Caso ele n√£o exista, o monitoramento de qualidade da API ser√° desativado.

3. **Visualizar Experimentos (MLflow):**
   
   ```bash
   mlflow ui
   # Acesse [http://127.0.0.1:5000](http://127.0.0.1:5000) para ver gr√°ficos e par√¢metros
   ```

4. **Subir a API:**
   
   ```bash
   uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
   ```

---

## üîå Documenta√ß√£o da API

A API possui 5 endpoints principais para ciclo de vida completo do modelo.

### 1. Infer√™ncia com Monitoramento (`POST /predict`)

Realiza a previs√£o e verifica se h√° **Data Drift**.

* **Input:** Lista de pre√ßos (float).
  * **Importante:** A lista deve conter **exatamente 60 valores** (correspondente ao `seq_length` configurado), representando os √∫ltimos 60 dias de fechamento para a previs√£o do dia seguinte.
* **Output:** Pre√ßo previsto e alerta de drift.

```json
// Resposta Exemplo
{
  "predicted_price": 12.85,
  "drift_warning": true,
  "drift_details": ["Alta volatilidade detectada (3x superior ao treino)."]
}
```

### 2. Treinamento (`POST /train`)

Dispara um novo treinamento em **background** (sem travar a API).

* **Input (Opcional):** Hiperpar√¢metros para sobrescrever o padr√£o.

```json
{
  "hyperparameters": {
    "num_epochs": 10,
    "learning_rate": 0.005
  }
}
```

### 3. Configura√ß√£o (`GET/POST /config`)

O endpoint /config permite o tuning din√¢mico de hiperpar√¢metros. Ao atualizar a configura√ß√£o e disparar o /train, o sistema realiza o ajuste fino (fine-tuning) do modelo sem necessidade de alterar o c√≥digo-fonte.

### 4. Recarregar Modelo (`POST /model/reload`)

Atualiza o modelo em mem√≥ria (Hot Reload) ap√≥s um retreino, sem reiniciar o servidor.

### 5. Sa√∫de (`GET /health`)

Monitora CPU, Mem√≥ria e disponibilidade dos artefatos.

---

## üìö Gloss√°rio T√©cnico

* **LSTM (Long Short-Term Memory):** Tipo de rede neural recorrente capaz de aprender depend√™ncias de longo prazo, ideal para s√©ries temporais (como pre√ßos de a√ß√µes).

* **Data Drift:** Ocorre quando as propriedades estat√≠sticas dos dados de entrada mudam de forma significativa em rela√ß√£o aos dados usados no treino. No mercado financeiro, isso pode ser causado por crises econ√¥micas ou mudan√ßas bruscas na volatilidade, o que pode invalidar as predi√ß√µes do modelo.

* **MAPE (Mean Absolute Percentage Error):** M√©trica que indica o erro m√©dio em porcentagem. Um MAPE de 1.56% significa que, em m√©dia, a previs√£o erra apenas 1.56% do valor real da a√ß√£o.

---

## ‚òÅÔ∏è Escalabilidade e Monitoramento (Proposta)

Para garantir a elasticidade da solu√ß√£o em ambiente produtivo de alta escala, prop√µe-se a seguinte arquitetura baseada em microsservi√ßos e orquestra√ß√£o:

1. **Orquestra√ß√£o e Auto-scaling:**
* **Horizontal Pod Autoscaler (HPA) no Kubernetes:** Configura√ß√£o de um HPA para monitorar m√©tricas de **CPU** e **Lat√™ncia de Requisi√ß√£o**.
* **Regra de Escala:** Caso a utiliza√ß√£o de CPU ultrapasse 70% ou a lat√™ncia m√©dia exceda um limite definido, o Kubernetes iniciar√° novas r√©plicas (Pods) da API automaticamente para suportar a carga.
2. **Arquitetura de Deploy e Balanceamento:**
* **Ingress Controller (Nginx):** Atua como o ponto de entrada √∫nico e **Load Balancer**, distribuindo o tr√°fego de forma inteligente entre os diversos Pods ativos da API, garantindo alta disponibilidade.
* **Servi√ßo de Treinamento Dedicado:** O endpoint `/train` deve ser desacoplado para um **Worker** ass√≠ncrono especializado.
3. **Desacoplamento de Processos Pesados:**
* **Fila de Mensagens (Redis/RabbitMQ):** Em produ√ß√£o, a requisi√ß√£o de treinamento n√£o √© executada pela API de infer√™ncia, mas enviada para uma fila.
* **Workers Ass√≠ncronos (Celery):** Inst√¢ncias dedicadas consomem essa fila para processar o treinamento de forma isolada, evitando que o consumo intensivo de recursos (CPU/GPU) do treino prejudique a performance e a lat√™ncia das previs√µes para o usu√°rio final.
4. **Monitoramento de Qualidade (Observabilidade):**
* **Detec√ß√£o de Drift:** O mecanismo de monitoramento implementado gera logs estruturados (`WARNING`) sempre que uma anomalia estat√≠stica √© detectada.
* **Dashboards de Qualidade:** Utiliza√ß√£o de ferramentas como **Fluentd** ou **Filebeat** para coletar esses logs e envi√°-los para um stack de visualiza√ß√£o (**Grafana/Kibana**), permitindo alertas em tempo real sobre a degrada√ß√£o da precis√£o do modelo.

---

## üë• Autores

* Fernando LFS ‚Äî [GitHub](https://github.com/fernando-lfs) | [LinkedIn](https://www.linkedin.com/in/fernando-lfs/)

---
