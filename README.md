# üìà Tech Challenge - Fase 4: Previs√£o de A√ß√µes com MLOps

> **Deep Learning & AI - FIAP**

Este projeto consiste em uma solu√ß√£o completa de **End-to-End Machine Learning** para prever o pre√ßo de fechamento de a√ß√µes da **CEMIG (CMIG4.SA)**. 

A solu√ß√£o abrange desde a coleta e pr√©-processamento de dados financeiros at√© o treinamento de uma rede neural **LSTM** (Long Short-Term Memory) utilizando **PyTorch Lightning** e **MLflow** , disponibilizando o modelo final atrav√©s de uma API **FastAPI** robusta e containerizada com **Docker**. O sistema conta ainda com suporte a treinamento ass√≠ncrono e monitoramento em tempo real de **Data Drift** para garantir a confiabilidade das previs√µes em produ√ß√£o.

---

## üöÄ Funcionalidades Principais

* **Coleta & Baseline:** Download autom√°tico via `yfinance` e gera√ß√£o de estat√≠sticas descritivas para detec√ß√£o de anomalias.
* **Treinamento Padronizado:** Pipeline utilizando `PyTorch Lightning` para organizar loops de treino/valida√ß√£o e `EarlyStopping`.
* **Rastreamento (Tracking):** Registro autom√°tico de hiperpar√¢metros, m√©tricas (Loss, MAPE) e artefatos (modelos `.pth`, gr√°ficos) via **MLflow**.
* **API Gerenci√°vel:** Interface RESTful que permite n√£o apenas prever, mas tamb√©m disparar **retreinos em background** e atualizar configura√ß√µes dinamicamente.
* **Observabilidade de Dados:** O endpoint de predi√ß√£o detecta automaticamente **Data Drift** (mudan√ßas bruscas de padr√£o ou volatilidade) comparando a entrada com o baseline de treino.
* **Escalabilidade:** Arquitetura desenhada para execu√ß√£o em containers e orquestra√ß√£o.

---

## üõ†Ô∏è Stack Tecnol√≥gico

* **Linguagem:** Python 3.11
* **Gerenciamento:** Poetry
* **Deep Learning:** PyTorch, PyTorch Lightning
* **MLOps:** MLflow
* **API:** FastAPI, Uvicorn, Pydantic
* **Dados:** Pandas, Numpy, Scikit-Learn, Yahoo Finance
* **Infraestrutura:** Docker

---

## üèóÔ∏è Arquitetura e Decis√µes T√©cnicas (ADR)

Para atender aos requisitos de qualidade de engenharia, as seguintes decis√µes foram tomadas:

1. **PyTorch Lightning:** Adotado para remover *boilerplate code* (loops manuais) e padronizar o c√≥digo de treinamento, facilitando a manuten√ß√£o e a reprodutibilidade.
2. **MLflow:** Escolhido como ferramenta de *Tracking* por ser agn√≥stico √† infraestrutura (roda localmente ou na nuvem) e permitir versionamento claro de cada experimento.
3. **FastAPI com BackgroundTasks:** Para o endpoint de treinamento (`/train`), utilizamos processamento ass√≠ncrono. Isso impede que uma requisi√ß√£o de treino bloqueie a API, mantendo-a responsiva para infer√™ncias simult√¢neas.
4. **Detec√ß√£o de Drift "In-App":** Optou-se por implementar um detector estat√≠stico leve dentro da pr√≥pria API (compara√ß√£o com Baseline JSON). Isso garante monitoramento de qualidade imediato sem a complexidade/custo de ferramentas externas pesadas (como Evidently AI) para este escopo acad√™mico.

---

## üìÇ Estrutura do Projeto

```text
/
‚îú‚îÄ‚îÄ api/                  # Aplica√ß√£o Web e Logs Centralizados
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Endpoints (Train, Predict, Config)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py       # Configura√ß√£o de Logging
‚îú‚îÄ‚îÄ data/                 # Data Lake (Raw e Processed)
‚îú‚îÄ‚îÄ mlruns/               # Registro local do MLflow (Metadados dos experimentos)
‚îú‚îÄ‚îÄ models/               # Artefatos: .pth, .joblib e baseline_stats.json
‚îú‚îÄ‚îÄ results/              # Gr√°ficos gerados
‚îú‚îÄ‚îÄ scripts/              # Pipelines ETL e Treino
‚îÇ   ‚îú‚îÄ‚îÄ 01_coleta_dados.py
‚îÇ   ‚îú‚îÄ‚îÄ 02_preprocess.py  # Gera dados normalizados e Baseline de Drift
‚îÇ   ‚îú‚îÄ‚îÄ 03_train.py       # Treino com Lightning + MLflow
‚îÇ   ‚îî‚îÄ‚îÄ 04_evaluate.py    # Avalia√ß√£o em dados de teste
‚îú‚îÄ‚îÄ src/                  # C√≥digo Fonte Reutiliz√°vel
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py
‚îÇ   ‚îî‚îÄ‚îÄ model.py
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ README.md
```

---

## üìà Performance e Resultados

O modelo final (LSTM com 2 camadas, 64 neur√¥nios) atingiu os seguintes resultados nos dados de teste:

| M√©trica                    | Valor     |
| -------------------------- | --------- |
| **MAPE** (Erro Percentual) | **1.56%** |
| **MAE** (Erro Absoluto)    | R$ 0.16   |
| **RMSE** (Erro Quadr√°tico) | R$ 0.19   |

> **Nota:** Todos os gr√°ficos de perda e m√©tricas detalhadas podem ser visualizados via `mlflow ui`.

---

## ‚ö° Como Executar o Projeto

### Op√ß√£o 1: Via Docker (Produ√ß√£o)

1. **Construir a imagem:**
   
   ```bash
   docker build -t lstm-mlops .
   ```

2. **Rodar o container:**
   
   ```bash
   docker run -d -p 8000:8000 --name api-lstm lstm-mlops
   ```

3. **Acessar:**
* Swagger UI: `http://localhost:8000/docs`

---

### Op√ß√£o 2: Execu√ß√£o Local (Desenvolvimento & Experimentos)

1. **Instalar depend√™ncias:**
   
   ```bash
   poetry install
   poetry shell
   ```

2. **Executar Pipeline Completo (ETL + Treino):**
   
   ```bash
   # 1. Coleta e Preprocessamento (Gera baseline_stats.json)
   python -m scripts.01_coleta_dados
   python -m scripts.02_preprocess
   # 2. Treinamento (Registra no MLflow)
   python -m scripts.03_train
   # 3. Avalia√ß√£o
   python -m scripts.04_evaluate
   ```

3. **Visualizar Experimentos (MLflow):**
   
   ```bash
   mlflow ui
   # Acesse [http://127.0.0.1:5000](http://127.0.0.1:5000) para ver gr√°ficos e par√¢metros
   ```

4. **Subir a API:**
   
   ```bash
   uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
   ```

---

## üîå Documenta√ß√£o da API

A API possui 5 endpoints principais para ciclo de vida completo do modelo.

### 1. Infer√™ncia com Monitoramento (`POST /predict`)

Realiza a previs√£o e verifica se h√° **Data Drift**.

* **Input:** Lista de pre√ßos (float).
* **Output:** Pre√ßo previsto e alerta de drift.

```json
// Resposta Exemplo
{
  "predicted_price": 12.85,
  "drift_warning": true,
  "drift_details": ["Alta volatilidade detectada (3x superior ao treino)."]
}
```

### 2. Treinamento (`POST /train`)

Dispara um novo treinamento em **background** (sem travar a API).

* **Input (Opcional):** Hiperpar√¢metros para sobrescrever o padr√£o.

```json
{
  "hyperparameters": {
    "num_epochs": 10,
    "learning_rate": 0.005
  }
}
```

### 3. Configura√ß√£o (`GET/POST /config`)

L√™ ou atualiza os hiperpar√¢metros globais usados nos pr√≥ximos treinos.

### 4. Recarregar Modelo (`POST /model/reload`)

Atualiza o modelo em mem√≥ria (Hot Reload) ap√≥s um retreino, sem reiniciar o servidor.

### 5. Sa√∫de (`GET /health`)

Monitora CPU, Mem√≥ria e disponibilidade dos artefatos.

---

## ‚òÅÔ∏è Escalabilidade e Monitoramento (Proposta)

Para garantir a elasticidade da solu√ß√£o em ambiente produtivo de alta demanda, prop√µe-se a seguinte arquitetura:

1. **Horizontal Pod Autoscaler (HPA) no Kubernetes:**
* Configura√ß√£o de um HPA monitorando a m√©trica de **CPU** e **Lat√™ncia**.
* **Regra:** Se a utiliza√ß√£o de CPU ultrapassar 70%, o Kubernetes inicia novas r√©plicas (Pods) da API automaticamente.
2. **Desacoplamento de Treino:**
* Em produ√ß√£o, o endpoint `/train` enviaria uma mensagem para uma fila (Redis/RabbitMQ).
* Workers dedicados (Celery) consumiriam essa fila para treinar o modelo, evitando impacto na performance da infer√™ncia.
3. **Monitoramento de Qualidade:**
* O mecanismo de *Drift* atual gera logs estruturados (`WARNING`).
* Ferramentas como **Fluentd** ou **Filebeat** coletariam esses logs para gerar alertas em dashboards (Grafana/Kibana) quando a taxa de drift excedesse um limiar seguro.

---

## üë• Autores

* Fernando LFS ‚Äî [GitHub](https://github.com/fernando-lfs) | [LinkedIn](https://www.linkedin.com/in/fernando-lfs/)

---
