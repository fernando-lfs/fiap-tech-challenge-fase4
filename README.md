
# üìà Tech Challenge - Fase 4: Previs√£o de A√ß√µes com MLOps

![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0-ee4c2c?style=for-the-badge&logo=pytorch)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Container-2496ed?style=for-the-badge&logo=docker)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-blue?style=for-the-badge&logo=mlflow)
![Pytest](https://img.shields.io/badge/Pytest-Testing-yellow?style=for-the-badge&logo=pytest)

> **P√≥s-Gradua√ß√£o em Deep Learning & AI - FIAP**

Este projeto apresenta uma solu√ß√£o completa de **End-to-End Machine Learning** para a previs√£o de pre√ßos de fechamento de a√ß√µes da **CEMIG (CMIG4.SA)**.

A arquitetura abrange desde a engenharia de dados at√© o deploy produtivo, utilizando **LSTM (Long Short-Term Memory)** para modelagem temporal, **MLflow** para rastreamento de experimentos e **FastAPI** para servir o modelo, tudo orquestrado via **Docker**.

---

## üöÄ Funcionalidades e Diferenciais

*   **Pipeline Automatizado:** Scripts modulares para ETL, Treinamento e Avalia√ß√£o.
*   **Deep Learning Moderno:** Uso de **PyTorch Lightning** para estruturar o c√≥digo de treino e garantir reprodutibilidade.
*   **API Inteligente (Drift Detection):** O endpoint de predi√ß√£o monitora estatisticamente a entrada. Se os dados desviarem do padr√£o de treino (ex: alta volatilidade), um alerta √© retornado no JSON de resposta.
*   **Treino Ass√≠ncrono:** Capacidade de retreinar o modelo em background (`BackgroundTasks`) sem bloquear a API.
*   **MLOps & Tracking:** Integra√ß√£o nativa com **MLflow** para registrar m√©tricas detalhadas (**MAE, RMSE, MAPE**), hiperpar√¢metros e artefatos do modelo.
*   **Qualidade de Software:** Su√≠te robusta de **testes de integra√ß√£o** (`pytest`) que valida a API, o carregamento de artefatos e a l√≥gica de detec√ß√£o de anomalias antes do deploy.
*   **Containeriza√ß√£o Segura:** Dockerfile otimizado rodando com **usu√°rio n√£o-root** (appuser) para mitigar riscos de seguran√ßa em produ√ß√£o.
*   **Documenta√ß√£o Interativa:** O Swagger UI vem pr√©-configurado com exemplos de dados e endpoints auxiliares para facilitar o teste manual.

---

## üèóÔ∏è Arquitetura e Decis√µes T√©cnicas (ADR)

| Componente | Escolha T√©cnica | Justificativa (Why?) |
| :--- | :--- | :--- |
| **Framework DL** | **PyTorch + Lightning** | Flexibilidade din√¢mica e remo√ß√£o de *boilerplate* (loops manuais), facilitando a manuten√ß√£o e uso de callbacks. |
| **Tracking** | **MLflow** | Padr√£o de mercado para rastreabilidade de experimentos (m√©tricas e par√¢metros). |
| **API** | **FastAPI** | Alta performance (ASGI), valida√ß√£o autom√°tica com Pydantic e suporte nativo a processamento ass√≠ncrono. |
| **Testes** | **Pytest + TestClient** | Padr√£o da ind√∫stria. O TestClient permite simular requisi√ß√µes √† API sem necessidade de subir o servidor, validando o ciclo de vida (`lifespan`) da aplica√ß√£o. |
| **Drift Detection** | **Estat√≠stica (In-App)** | Implementa√ß√£o leve baseada em estat√≠sticas descritivas (Baseline JSON). Evita a complexidade de ferramentas externas pesadas para este escopo. |
| **Configura√ß√£o** | **Single Source of Truth** | Uso de `src/config.py` centralizado para evitar "n√∫meros m√°gicos" e inconsist√™ncias de caminhos. |

---

## ‚ö° Guia de Instala√ß√£o e Execu√ß√£o

### Pr√©-requisitos
*   **Docker** (Recomendado para execu√ß√£o isolada e avalia√ß√£o).
*   **Python 3.11+** e **Poetry** (Para desenvolvimento local).

### 1. Clonar o Reposit√≥rio
O primeiro passo √© obter o c√≥digo-fonte em sua m√°quina local.

```bash
git clone https://github.com/fernando-lfs/fiap-tech-challenge-fase4.git
cd fiap-tech-challenge-fase4
```

### 2. Configura√ß√£o do Ambiente
Voc√™ pode executar o projeto via **Docker** (Recomendado para avalia√ß√£o r√°pida) ou **Localmente** (Para desenvolvimento).

#### Op√ß√£o A: Via Docker (Produ√ß√£o/Avalia√ß√£o)
Sobe a API pronta para uso, contendo o modelo pr√©-treinado.

```bash
# 1. Construir a Imagem
docker build -t lstm-mlops .

# 2. Rodar o Container
docker run -d -p 8000:8000 --name api-lstm lstm-mlops
```
*Acesse a documenta√ß√£o interativa em:* [http://localhost:8000/docs](http://localhost:8000/docs)

---

#### Op√ß√£o B: Execu√ß√£o Local (Desenvolvimento)
Recomendado se voc√™ deseja rodar o pipeline de treinamento passo a passo.

**Passo 1: Instalar Depend√™ncias**
```bash
# Se estiver usando Poetry (Recomendado)
poetry install
poetry shell

# OU via pip tradicional
pip install -r requirements.txt
```

**Passo 2: Executar o Pipeline de Dados e Treino**
Siga a ordem l√≥gica dos scripts para reproduzir o ciclo de vida do modelo:

```bash
# 1. Coleta (Yahoo Finance) -> Gera data/01_raw/*.csv
python -m scripts.01_coleta_dados

# 2. Pr√©-processamento -> Gera data/02_processed/*.npy e baseline_stats.json
# IMPORTANTE: Essencial para o funcionamento do Drift Detection
python -m scripts.02_preprocess

# 3. Treinamento -> Gera models/lstm_model.pth e registra no MLflow
python -m scripts.03_train

# 4. Avalia√ß√£o -> Gera m√©tricas e gr√°ficos em results/
python -m scripts.04_evaluate
```

**Passo 3: Iniciar a API**
```bash
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

---

## üîå Documenta√ß√£o da API

Abaixo, uma vis√£o geral de todos os endpoints dispon√≠veis. Para detalhes de implementa√ß√£o (JSON Body/Response), consulte as se√ß√µes detalhadas logo ap√≥s a tabela.

| M√©todo | Endpoint | Descri√ß√£o |
| :--- | :--- | :--- |
| `POST` | **/predict** | **Principal:** Realiza a predi√ß√£o de pre√ßo (D+1) e detecta Data Drift. |
| `POST` | **/train** | **Principal:** Dispara retreino ou tuning de hiperpar√¢metros em background. |
| `GET` | **/model/info** | **Principal:** Exibe m√©tricas de performance (MAE, RMSE) do modelo atual. |
| `GET` | **/sample-data** | Retorna dados reais de teste para facilitar o uso do `/predict`. |
| `GET` | **/health** | Health Check (Liveness Probe) para monitoramento (K8s/Docker). |
| `GET` | **/config** | Consulta os hiperpar√¢metros carregados na mem√≥ria. |
| `POST` | **/config** | Atualiza hiperpar√¢metros na mem√≥ria (sem disparar treino). |
| `POST` | **/model/reload** | For√ßa o recarregamento dos arquivos `.pth` e `.joblib` do disco. |
| `GET` | **/** | Verifica se a API est√° online (Root). |

### Detalhamento dos Endpoints Principais

#### 1. Predi√ß√£o de Pre√ßo (`POST /predict`)
Recebe uma janela hist√≥rica e prev√™ o fechamento do dia seguinte (D+1).

*   **Regra de Neg√≥cio:** √â obrigat√≥rio enviar **exatamente 60 pre√ßos** (dias), correspondentes √† janela de treinamento da LSTM.
*   **Drift:** Se os dados fugirem do padr√£o estat√≠stico do treino, `drift_warning` ser√° `true`.

**Exemplo de Requisi√ß√£o (Body):**
```json
{
  "last_prices": [10.5, 10.6, ..., 11.2] // Lista com 60 floats
}
```

**Exemplo de Resposta (Sucesso):**
```json
{
  "predicted_price": 12.45,
  "drift_warning": false,
  "drift_details": []
}
```

#### 2. Treinamento e Tuning (`POST /train`)
Dispara um job de retreino em background. Permite ajuste fino de hiperpar√¢metros (Tuning).

**Exemplo de Requisi√ß√£o (Tuning):**
```json
{
  "hyperparameters": {
    "learning_rate": 0.0005,
    "num_epochs": 100,
    "hidden_size": 128
  }
}
```

#### 3. Monitoramento (`GET /model/info`)
Retorna o estado atual do modelo em produ√ß√£o e m√©tricas da √∫ltima avalia√ß√£o.

**Exemplo de Resposta:**
```json
{
  "version": "0.1.0",
  "current_params": {
    "seq_length": 60,
    "hidden_size": 64
  },
  "metrics": {
    "mae": 0.20,
    "rmse": 0.25,
    "mape": 1.94
  }
}
```

---

## üìÇ Estrutura do Projeto

```text
/
‚îú‚îÄ‚îÄ api/                  # Aplica√ß√£o Web (FastAPI)
‚îú‚îÄ‚îÄ data/                 # Data Lake Local (Raw e Processed)
‚îú‚îÄ‚îÄ mlruns/               # Registro de Experimentos MLflow
‚îú‚îÄ‚îÄ models/               # Artefatos Persistidos (.pth, .joblib, .json)
‚îú‚îÄ‚îÄ results/              # Gr√°ficos de Performance
‚îú‚îÄ‚îÄ scripts/              # Pipeline de Execu√ß√£o (ETL, Train, Eval)
‚îú‚îÄ‚îÄ src/                  # C√≥digo Fonte Compartilhado (Model, Dataset, Config)
‚îú‚îÄ‚îÄ tests/                # Testes de Integra√ß√£o
‚îú‚îÄ‚îÄ Dockerfile            # Defini√ß√£o da Imagem
‚îú‚îÄ‚îÄ pyproject.toml        # Gerenciamento de Depend√™ncias (Poetry)
‚îî‚îÄ‚îÄ README.md             # Documenta√ß√£o
```

---

## üìà Resultados Obtidos

O modelo atual (LSTM 2-Layers, Hidden=64) apresentou nos dados de teste:

| M√©trica | Valor | Descri√ß√£o |
| :--- | :--- | :--- |
| **MAPE** | **2.24%** | Erro percentual m√©dio absoluto. |
| **RMSE** | **0.28** | Raiz do erro quadr√°tico m√©dio (na escala real em R$). |
| **MAE**  | **0.23** | Erro absoluto m√©dio (na escala real em R$). |

---

## ‚òÅÔ∏è Proposta de Escalabilidade

Para um cen√°rio de alta demanda, a arquitetura evoluiria para:

1.  **Kubernetes (K8s):** Orquestra√ß√£o dos containers com HPA (Horizontal Pod Autoscaler) baseado em uso de CPU.
2.  **Fila de Mensagens (RabbitMQ/Celery):** O endpoint `/train` deixaria de processar localmente e enviaria jobs para workers dedicados em GPUs isoladas.

---

## üë• Autor

**Fernando Luiz Ferreira**
```