import torch
import joblib
import numpy as np
import pandas as pd  # Adicionado para corrigir o warning do Scaler
import psutil
import time
import sys
import os
import json
import importlib
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from pydantic import BaseModel, Field
from typing import List, Dict, Optional

# Adiciona raiz ao path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from src.model import LSTMModel
from src import config
from api import logger, __app__, __version__

# --- Importa√ß√£o Din√¢mica do Script de Treino ---
training_script = importlib.import_module("scripts.03_train")

# --- Vari√°veis Globais de Estado ---
ml_components = {
    "model": None,
    "scaler": None,
    "baseline_stats": None,
    "training_active": False,
}

# --- Metadados para Documenta√ß√£o (Tags) ---
tags_metadata = [
    {
        "name": "Inference",
        "description": "Endpoints para predi√ß√£o de pre√ßos e gera√ß√£o de dados de exemplo.",
    },
    {
        "name": "Training & Tuning",
        "description": "Funcionalidades de retreino do modelo e ajuste de hiperpar√¢metros.",
    },
    {
        "name": "Monitoring",
        "description": "Health checks, m√©tricas de performance e informa√ß√µes do sistema.",
    },
    {
        "name": "Management",
        "description": "Gerenciamento de configura√ß√µes e recarga de artefatos (Hot Reload).",
    },
]


# --- L√≥gica de Carregamento (Lifespan) ---
def load_artifacts():
    """Carrega os artefatos de ML na mem√≥ria."""
    try:
        # 1. Carregar Scaler
        if os.path.exists(config.SCALER_PATH):
            ml_components["scaler"] = joblib.load(config.SCALER_PATH)
            logger.info("Scaler carregado com sucesso.")

        # 2. Carregar Estat√≠sticas de Drift
        if os.path.exists(config.STATS_PATH):
            with open(config.STATS_PATH, "r") as f:
                ml_components["baseline_stats"] = json.load(f)
            logger.info("Baseline estat√≠stico carregado.")
        else:
            logger.warning(
                "Baseline stats n√£o encontrado. Monitoramento de Drift inativo."
            )

        # 3. Carregar Modelo
        if os.path.exists(config.MODEL_PATH):
            params = training_script.CURRENT_PARAMS
            model = LSTMModel(
                input_size=1,
                hidden_size=int(params["hidden_size"]),
                num_layers=int(params["num_layers"]),
            )
            # Usa config.DEVICE para consist√™ncia
            model.load_state_dict(
                torch.load(config.MODEL_PATH, map_location=config.DEVICE)
            )
            model.to(config.DEVICE)
            model.eval()
            ml_components["model"] = model
            logger.info("Modelo LSTM carregado com sucesso.")
        else:
            logger.warning("Arquivo de modelo n√£o encontrado. API em modo degradado.")

    except Exception as e:
        logger.error(f"Erro cr√≠tico no carregamento de artefatos: {e}")


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Executado na inicializa√ß√£o
    logger.info("Inicializando componentes de ML...")
    load_artifacts()
    yield
    # Executado no desligamento (limpeza se necess√°rio)
    logger.info("Desligando API...")


app = FastAPI(
    title=__app__,
    description="""
    ## üöÄ API de Previs√£o de A√ß√µes (LSTM) - Tech Challenge
    
    Esta API fornece servi√ßos de Machine Learning para previs√£o de pre√ßos de fechamento de a√ß√µes (CMIG4).
    
    ### Funcionalidades Principais:
    * **Predi√ß√£o:** Estima o pre√ßo do dia seguinte (D+1) com base em uma janela hist√≥rica.
    * **Monitoramento:** Detecta *Data Drift* (mudan√ßas no padr√£o dos dados) em tempo real.
    * **MLOps:** Permite retreino e tuning de hiperpar√¢metros em background.
    """,
    version=__version__,
    openapi_tags=tags_metadata,
    lifespan=lifespan,
)


# --- Pydantic Models ---
class PredictionRequest(BaseModel):
    last_prices: List[float] = Field(
        ...,
        description="Lista contendo exatamente 60 pre√ßos de fechamento hist√≥ricos (float). Aten√ß√£o, a predi√ß√£o falhar√° se o tamanho for diferente.",
        min_length=60,
        max_length=60,
    )

    # Configura√ß√£o para melhorar a usabilidade no Swagger UI
    # AJUSTE: Valores alterados para ~7.0 para evitar Drift Warning falso positivo
    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "last_prices": [
                        7.0 + (i * 0.01) for i in range(60)
                    ]  # Gera 60 valores pr√≥ximos da m√©dia hist√≥rica (7.0 - 7.6)
                }
            ]
        }
    }


class TrainRequest(BaseModel):
    hyperparameters: Optional[Dict[str, float]] = Field(
        default=None,
        description="Dicion√°rio opcional de hiperpar√¢metros. Se fornecido, sobrescreve os padr√µes para o novo treino.",
        examples=[
            {
                "learning_rate": 0.001,
                "num_epochs": 50,
                "hidden_size": 64,
                "batch_size": 32,
            }
        ],
    )

    def validate_params(self):
        """Valida√ß√£o manual adicional se necess√°rio"""
        if self.hyperparameters:
            if self.hyperparameters.get("learning_rate", 1) <= 0:
                raise ValueError("learning_rate deve ser maior que 0")
            if self.hyperparameters.get("num_epochs", 1) < 1:
                raise ValueError("num_epochs deve ser pelo menos 1")


class ConfigResponse(BaseModel):
    current_params: Dict[str, float]


# --- Middleware ---
@app.middleware("http")
async def monitor_performance(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    logger.info(
        f"Path: {request.url.path} | Method: {request.method} | "
        f"Status: {response.status_code} | Latency: {process_time:.4f}s"
    )
    return response


# --- L√≥gica de Neg√≥cio Auxiliar ---


def detect_drift(input_data: List[float]) -> Dict:
    stats = ml_components["baseline_stats"]
    if not stats:
        return {"drift": False, "reason": "Baseline not loaded"}

    input_arr = np.array(input_data)
    drift_reasons = []

    # Margem de toler√¢ncia de 10%
    margin = 0.10
    limit_max = stats["max"] * (1 + margin)
    limit_min = stats["min"] * (1 - margin)

    if np.max(input_arr) > limit_max:
        drift_reasons.append(
            f"Input Max ({np.max(input_arr):.2f}) > Hist√≥rico ({limit_max:.2f})"
        )

    if np.min(input_arr) < limit_min:
        drift_reasons.append(
            f"Input Min ({np.min(input_arr):.2f}) < Hist√≥rico ({limit_min:.2f})"
        )

    input_std = np.std(input_arr)
    if input_std > (stats["std"] * 3):
        drift_reasons.append("Alta volatilidade detectada (3x superior ao treino).")

    is_drift = len(drift_reasons) > 0
    if is_drift:
        logger.warning(f"DATA DRIFT DETECTADO: {drift_reasons}")

    return {"drift": is_drift, "reasons": drift_reasons}


def background_train_task(params: dict):
    ml_components["training_active"] = True
    try:
        logger.info("Iniciando treino em background...")
        training_script.train(override_params=params)
        # Recarrega o modelo ap√≥s o treino
        load_artifacts()
    except Exception as e:
        logger.error(f"Erro treino background: {e}")
    finally:
        ml_components["training_active"] = False


# --- Endpoints ---


@app.get("/", tags=["Monitoring"])
def root():
    """
    **Verifica o status b√°sico da API.**

    Retorna o nome da aplica√ß√£o, vers√£o e status online.
    """
    return {"app": __app__, "version": __version__, "status": "online"}


@app.get("/health", tags=["Monitoring"])
def health_check():
    """
    **Health Check Completo (Liveness Probe).**

    Utilizado para monitoramento de infraestrutura. Verifica:
    1. Se o modelo est√° carregado na mem√≥ria.
    2. Se o monitoramento de Data Drift est√° ativo (estat√≠sticas carregadas).
    3. Se h√° um treinamento em andamento.
    4. Consumo de recursos (CPU e Mem√≥ria).
    """
    try:
        cpu = psutil.cpu_percent()
        mem = psutil.virtual_memory()
        return {
            "status": "healthy" if ml_components["model"] else "degraded",
            "drift_monitoring": ml_components["baseline_stats"] is not None,
            "training_active": ml_components["training_active"],
            "resources": {"cpu": cpu, "memory": mem.percent},
        }
    except Exception as e:
        return {"status": "unhealthy", "detail": str(e)}


@app.get("/sample-data", tags=["Inference"])
def get_sample_data():
    """
    **Obter Dados Reais de Teste.**

    Retorna os √∫ltimos 60 pre√ßos de fechamento do dataset de teste (dados reais).

    **Objetivo:** Facilitar o teste manual do endpoint `/predict`.
    O usu√°rio pode copiar o retorno deste endpoint e colar no corpo da requisi√ß√£o de predi√ß√£o.
    """
    try:
        if not os.path.exists(config.TEST_DATA_PATH) or not ml_components["scaler"]:
            raise HTTPException(
                status_code=404, detail="Dados de teste ou Scaler n√£o encontrados."
            )

        # Carrega dados normalizados
        test_data = np.load(config.TEST_DATA_PATH)

        # Pega os √∫ltimos 60 pontos
        seq_len = int(training_script.CURRENT_PARAMS["seq_length"])
        if len(test_data) < seq_len:
            raise HTTPException(
                status_code=400, detail="Dados insuficientes para gerar amostra."
            )

        sample_scaled = test_data[-seq_len:]

        # Desnormaliza para valores reais (R$)
        scaler = ml_components["scaler"]
        sample_real = scaler.inverse_transform(sample_scaled).flatten().tolist()

        return {
            "description": "√öltimos 60 pre√ßos de fechamento do dataset de teste.",
            "last_prices": [round(x, 2) for x in sample_real],
        }
    except Exception as e:
        logger.error(f"Erro ao gerar sample data: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post(
    "/predict",
    tags=["Inference"],
    responses={
        200: {"description": "Predi√ß√£o realizada com sucesso."},
        400: {
            "description": "ERRO DE VALIDA√á√ÉO: Lista de entrada com tamanho incorreto (deve ser 60)."
        },
        503: {"description": "Modelo n√£o carregado (Servi√ßo Indispon√≠vel)."},
    },
)
def predict_next_day(request: PredictionRequest):
    """
    **Realizar Predi√ß√£o de Pre√ßo (D+1).**

    Recebe uma janela hist√≥rica de pre√ßos e retorna a previs√£o para o pr√≥ximo dia.

    **‚ö†Ô∏è REQUISITO OBRIGAT√ìRIO:**
    * O corpo da requisi√ß√£o deve conter uma lista `last_prices` com **exatamente 60 valores** num√©ricos (float).
    * Valores pr√©-preenchidos est√£o dispon√≠veis no bot√£o "Try it out" apenas para teste de conectividade.
    * Para um teste real, utilize os dados do endpoint `/sample-data`.

    **Funcionalidades:**
    * Normaliza os dados de entrada.
    * Executa a infer√™ncia no modelo LSTM.
    * **Detecta Data Drift:** Analisa se os dados de entrada fogem estatisticamente do padr√£o de treino.
    """
    model = ml_components["model"]
    scaler = ml_components["scaler"]

    if not model or not scaler:
        raise HTTPException(
            status_code=503,
            detail="Servi√ßo indispon√≠vel (Modelo ou Scaler n√£o carregados).",
        )

    input_data = request.last_prices
    expected_length = int(training_script.CURRENT_PARAMS["seq_length"])

    if len(input_data) != expected_length:
        raise HTTPException(
            status_code=400,
            detail=f"Esperado {expected_length} pre√ßos. Recebido: {len(input_data)}.",
        )

    drift_info = detect_drift(input_data)

    try:
        # CORRE√á√ÉO: Criar DataFrame para evitar UserWarning do sklearn
        # O scaler foi treinado com DataFrame, ent√£o espera nomes de colunas.
        input_df = pd.DataFrame(input_data, columns=[config.FEATURE_COLUMN])

        # Transforma usando o DataFrame (mant√©m nomes das features)
        input_scaled = scaler.transform(input_df)

        sequence = (
            torch.tensor(input_scaled, dtype=torch.float32)
            .unsqueeze(0)
            .to(config.DEVICE)
        )

        with torch.no_grad():
            prediction_scaled = model(sequence)

        prediction_val = scaler.inverse_transform(prediction_scaled.cpu().numpy())
        result = float(prediction_val[0][0])

        return {
            "predicted_price": round(result, 2),
            "drift_warning": drift_info["drift"],
            "drift_details": drift_info["reasons"],
        }

    except Exception as e:
        logger.error(f"Erro na predi√ß√£o: {e}")
        raise HTTPException(status_code=500, detail="Erro interno no servidor.")


@app.post(
    "/train",
    tags=["Training & Tuning"],
    status_code=202,
    responses={
        202: {"description": "Treinamento iniciado em background."},
        409: {"description": "J√° existe um treinamento em andamento."},
    },
)
def trigger_training(request: TrainRequest, background_tasks: BackgroundTasks):
    """
    **Iniciar Treinamento e Tuning.**

    Dispara um processo ass√≠ncrono (Background Task) para retreinar o modelo.

    **Tuning de Hiperpar√¢metros:**
    * Voc√™ pode enviar novos hiperpar√¢metros no corpo da requisi√ß√£o (ex: `learning_rate`, `num_epochs`).
    * Se nenhum par√¢metro for enviado, o treino usar√° a configura√ß√£o padr√£o.

    **Nota:** O modelo em mem√≥ria ser√° atualizado automaticamente ao final do treino.
    """
    # Valida√ß√£o l√≥gica extra (al√©m da tipagem)
    try:
        request.validate_params()
    except ValueError as ve:
        raise HTTPException(status_code=400, detail=str(ve))

    if ml_components["training_active"]:
        raise HTTPException(status_code=409, detail="Treino j√° est√° em andamento.")

    params = request.hyperparameters or {}
    background_tasks.add_task(background_train_task, params)
    return {"status": "processing", "message": "Treino/Tuning iniciado em background."}


@app.get("/config", tags=["Management"], response_model=ConfigResponse)
def get_config():
    """
    **Consultar Configura√ß√£o Atual.**

    Retorna os hiperpar√¢metros que est√£o sendo utilizados pelo modelo carregado atualmente.
    """
    return {"current_params": training_script.CURRENT_PARAMS}


@app.get("/model/info", tags=["Monitoring"])
def get_model_info():
    """
    **Informa√ß√µes Detalhadas do Modelo.**

    Retorna metadados sobre o modelo em produ√ß√£o, incluindo:
    * Vers√£o da API.
    * Hiperpar√¢metros atuais.
    * **M√©tricas de Performance (MAE, RMSE):** Obtidas da √∫ltima avalia√ß√£o realizada no conjunto de teste.
    """
    info = {
        "version": __version__,
        "current_params": training_script.CURRENT_PARAMS,
        "metrics": None,
    }

    # Tenta carregar m√©tricas salvas pelo script de avalia√ß√£o
    if os.path.exists(config.METRICS_PATH):
        try:
            with open(config.METRICS_PATH, "r") as f:
                info["metrics"] = json.load(f)
        except Exception as e:
            logger.warning(f"Falha ao ler m√©tricas: {e}")
            info["metrics_error"] = "N√£o foi poss√≠vel ler metrics.json"
    else:
        info["metrics_status"] = (
            "M√©tricas n√£o dispon√≠veis (Execute o script 04_evaluate.py)"
        )

    return info


@app.post("/config", tags=["Management"])
def update_config(request: TrainRequest):
    """
    **Atualizar Configura√ß√£o Global.**

    Atualiza os hiperpar√¢metros na mem√≥ria sem disparar um treinamento imediato.
    √ötil para preparar uma configura√ß√£o antes de chamar o endpoint `/train`.
    """
    if request.hyperparameters:
        training_script.CURRENT_PARAMS.update(request.hyperparameters)
    return {
        "message": "Configura√ß√£o atualizada.",
        "current_params": training_script.CURRENT_PARAMS,
    }


@app.post("/model/reload", tags=["Management"])
def reload_model():
    """
    **Hot Reload de Artefatos.**

    For√ßa o recarregamento do modelo (`.pth`) e do scaler (`.joblib`) do disco para a mem√≥ria.
    √ötil caso voc√™ tenha substitu√≠do os arquivos manualmente e queira atualizar a API sem reiniciar o container.
    """
    load_artifacts()
    return {"message": "Artefatos recarregados."}
